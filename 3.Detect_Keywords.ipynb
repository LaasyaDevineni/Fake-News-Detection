{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xguiqy41hfTB",
        "outputId": "a1f164b9-538f-4f82-b743-415095e715c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"cleaned_dataset.csv\")\n",
        "\n",
        "# Download required NLTK resources (if not already downloaded)\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "nltk.download(\"punkt\", quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set of English stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Initialize counters for titles and text\n",
        "title_counter = Counter()\n",
        "text_counter = Counter()\n",
        "\n",
        "# Tokenize titles and texts, and update counters for \"Fake\" labels\n",
        "for title, text, label in zip(data[\"title\"], data[\"text\"], data[\"label\"]):\n",
        "    # Check if label is \"Fake\" and title/text are valid strings\n",
        "    if label == \"Fake\" and isinstance(title, str) and isinstance(text, str):\n",
        "        title_words = [\n",
        "            word.lower()\n",
        "            for word in word_tokenize(title)\n",
        "            if word.isalpha() and word.lower() not in stop_words\n",
        "        ]\n",
        "        text_words = [\n",
        "            word.lower()\n",
        "            for word in word_tokenize(text)\n",
        "            if word.isalpha() and word.lower() not in stop_words\n",
        "        ]\n",
        "        title_counter.update(title_words)\n",
        "        text_counter.update(text_words)\n"
      ],
      "metadata": {
        "id": "d7D-11lqi-ZQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get keywords\n",
        "top_keywords_title = title_counter.most_common(5)\n",
        "top_keywords_text = text_counter.most_common(5)"
      ],
      "metadata": {
        "id": "BYPDg7C1jCw3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 5 Keywords Associated with Fake News Titles:\")\n",
        "for keyword, count in top_keywords_title:\n",
        "    print(f\"{keyword}: {count} times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbw3Y3vljOXm",
        "outputId": "b33ff405-2147-4440-ceda-b13d9d99a65e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Keywords Associated with Fake News Titles:\n",
            "trump: 135 times\n",
            "hillary: 129 times\n",
            "clinton: 121 times\n",
            "title: 91 times\n",
            "us: 59 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 5 Keywords Associated with Fake News Texts:\")\n",
        "for keyword, count in top_keywords_text:\n",
        "    print(f\"{keyword}: {count} times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2dx0A4XjRUh",
        "outputId": "f7aef55f-0718-4508-b655-b7a89b2b6d40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Keywords Associated with Fake News Texts:\n",
            "clinton: 1990 times\n",
            "trump: 1975 times\n",
            "one: 1419 times\n",
            "us: 1385 times\n",
            "said: 1359 times\n"
          ]
        }
      ]
    }
  ]
}