{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y1UmM1YHmjyP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"cleaned_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the text column\n",
        "print(\"Missing values in 'text':\", data['text'].isna().sum())\n",
        "\n",
        "# Extract keywords for fake news and handle NaN values\n",
        "fake_news_data = data[data['label'] == \"Fake\"]\n",
        "\n",
        "# Drop rows with NaN in 'text' or fill them with a placeholder\n",
        "fake_news_data = fake_news_data.dropna(subset=['text'])\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6YSeVbhnjy5",
        "outputId": "d45bd67c-59a2-47bd-a3a2-690ab2136645"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'text': 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the text data\n",
        "X = vectorizer.fit_transform(fake_news_data[\"text\"])\n",
        "word_frequencies = X.toarray().sum(axis=0)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "keywords = set(feature_names[word_frequencies.argsort()[-10:][::-1]])\n",
        "\n",
        "# Count occurrences of sites\n",
        "site_counts = data[\"site_url\"].value_counts()\n",
        "fake_site_counts = data[data[\"label\"] == \"Fake\"][\"site_url\"].value_counts()\n",
        "fake_news_percentage = (fake_site_counts / site_counts).fillna(0)"
      ],
      "metadata": {
        "id": "VqU1RuYAnoDc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def fakenewsprediction(title, news_source):\n",
        "    title_contains_keyword = any(keyword in title.lower() for keyword in keywords)\n",
        "    source_fake_percentage = fake_news_percentage.get(news_source, 0.0)\n",
        "\n",
        "    if title_contains_keyword and source_fake_percentage > 0.5:\n",
        "        return \"Fake News\"\n",
        "    return \"Real News\"\n",
        "\n",
        "# Example prediction\n",
        "text_input = \"Breaking: election week is over\"\n",
        "source_input = \"der-postillon.com\"\n",
        "prediction = fakenewsprediction(text_input, source_input)\n",
        "print(f\"Prediction: {prediction}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA2V-MCbnsLl",
        "outputId": "952ac59a-27ec-440c-da40-6cc4f7d12b8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Fake News\n"
          ]
        }
      ]
    }
  ]
}